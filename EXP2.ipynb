{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3VEwTEt3KxLu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_dataset = torchvision.datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=True,\n",
        "    transform=torchvision.transforms.ToTensor(),\n",
        "    download=True\n",
        ")\n",
        "\n",
        "val_dataset = torchvision.datasets.MNIST(\n",
        "    root='./data',\n",
        "    train=False,\n",
        "    transform=torchvision.transforms.ToTensor(),\n",
        "    download=True\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoEM_koeZdFk",
        "outputId": "943bdf89-9d30-4720-b878-2dab04db2328"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:01<00:00, 5.09MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 132kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.26MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 9.96MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader   = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7o2Jzy5GZd9K"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot(labels, num_classes=10):\n",
        "    m = labels.shape[0]\n",
        "    encoded = np.zeros((num_classes, m))\n",
        "    encoded[labels, np.arange(m)] = 1\n",
        "    return encoded\n"
      ],
      "metadata": {
        "id": "DryVUsQuac9v"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork:\n",
        "    def __init__(self, lr=0.01):\n",
        "        self.lr = lr\n",
        "\n",
        "        self.W1 = np.random.randn(10, 784) * 0.01\n",
        "        self.b1 = np.zeros((10, 1))\n",
        "\n",
        "        self.W2 = np.random.randn(10, 10) * 0.01\n",
        "        self.b2 = np.zeros((10, 1))\n",
        "\n",
        "    def relu(self, Z):\n",
        "        return np.maximum(0, Z)\n",
        "\n",
        "    def relu_derivative(self, Z):\n",
        "        return (Z > 0).astype(float)\n",
        "\n",
        "    def softmax(self, Z):\n",
        "        exp = np.exp(Z - np.max(Z, axis=0, keepdims=True))\n",
        "        return exp / np.sum(exp, axis=0, keepdims=True)\n",
        "\n",
        "    def forward(self, X):\n",
        "        self.Z1 = self.W1 @ X + self.b1\n",
        "        self.A1 = self.relu(self.Z1)\n",
        "\n",
        "        self.Z2 = self.W2 @ self.A1 + self.b2\n",
        "        self.A2 = self.softmax(self.Z2)\n",
        "\n",
        "        return self.A2\n",
        "\n",
        "    def compute_loss(self, Y, A2):\n",
        "        m = Y.shape[1]\n",
        "        return -np.sum(Y * np.log(A2 + 1e-8)) / m\n",
        "\n",
        "    def backward(self, X, Y):\n",
        "        m = X.shape[1]\n",
        "\n",
        "        dZ2 = self.A2 - Y\n",
        "        dW2 = (1 / m) * dZ2 @ self.A1.T\n",
        "        db2 = (1 / m) * np.sum(dZ2, axis=1, keepdims=True)\n",
        "\n",
        "        dZ1 = (self.W2.T @ dZ2) * self.relu_derivative(self.Z1)\n",
        "        dW1 = (1 / m) * dZ1 @ X.T\n",
        "        db1 = (1 / m) * np.sum(dZ1, axis=1, keepdims=True)\n",
        "\n",
        "        self.dW1, self.db1 = dW1, db1\n",
        "        self.dW2, self.db2 = dW2, db2\n",
        "\n",
        "    def update_parameters(self):\n",
        "        self.W1 -= self.lr * self.dW1\n",
        "        self.b1 -= self.lr * self.db1\n",
        "        self.W2 -= self.lr * self.dW2\n",
        "        self.b2 -= self.lr * self.db2\n",
        "\n",
        "    def predict(self, X):\n",
        "        A2 = self.forward(X)\n",
        "        return np.argmax(A2, axis=0)\n",
        "\n",
        "    def evaluate(self, X, labels):\n",
        "        preds = self.predict(X)\n",
        "        return np.mean(preds == labels)\n",
        "\n"
      ],
      "metadata": {
        "id": "FSEPpYsqomQk"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn = NeuralNetwork(lr=0.05)\n",
        "epochs = 5\n"
      ],
      "metadata": {
        "id": "J7BO1RzupTA2"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "    losses = []\n",
        "    accs = []\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images = images.cpu().numpy()\n",
        "        labels = labels.cpu().numpy()\n",
        "\n",
        "        X = images.reshape(images.shape[0], -1).T\n",
        "        Y = one_hot(labels)\n",
        "\n",
        "        A2 = nn.forward(X)\n",
        "\n",
        "        loss = nn.compute_loss(Y, A2)\n",
        "        losses.append(loss)\n",
        "\n",
        "        nn.backward(X, Y)\n",
        "        nn.update_parameters()\n",
        "\n",
        "        acc = nn.evaluate(X, labels)\n",
        "        accs.append(acc)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}\")\n",
        "    print(f\"Train Loss: {np.mean(losses):.4f}\")\n",
        "    print(f\"Train Acc : {np.mean(accs)*100:.2f}%\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAUYDygVsA0E",
        "outputId": "a4d065db-24b5-4306-8eb8-0a105da5e45b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "Train Loss: 0.9815\n",
            "Train Acc : 71.94%\n",
            "\n",
            "Epoch 2\n",
            "Train Loss: 0.3621\n",
            "Train Acc : 91.01%\n",
            "\n",
            "Epoch 3\n",
            "Train Loss: 0.3178\n",
            "Train Acc : 92.13%\n",
            "\n",
            "Epoch 4\n",
            "Train Loss: 0.2951\n",
            "Train Acc : 92.75%\n",
            "\n",
            "Epoch 5\n",
            "Train Loss: 0.2813\n",
            "Train Acc : 93.15%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_acc = []\n",
        "val_loss = []\n",
        "\n",
        "for images, labels in val_loader:\n",
        "    images = images.cpu().numpy()\n",
        "    labels = labels.cpu().numpy()\n",
        "\n",
        "    X = images.reshape(images.shape[0], -1).T\n",
        "    Y = one_hot(labels)\n",
        "\n",
        "    A2 = nn.forward(X)\n",
        "    val_loss.append(nn.compute_loss(Y, A2))\n",
        "    val_acc.append(nn.evaluate(X, labels))\n",
        "\n",
        "print(f\"Validation Loss: {np.mean(val_loss):.4f}\")\n",
        "print(f\"Validation Acc : {np.mean(val_acc)*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s885O8njsCSO",
        "outputId": "855111d5-bd54-4351-93ce-7c099f6274f2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.2642\n",
            "Validation Acc : 92.49%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xO7aqP3jsQi2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}